"""
Student-triggered on-demand AI content generation endpoints
Students can generate Summary, Q&A, and Podcast for PUBLIC books only
First student to generate creates it for everyone
"""
from fastapi import APIRouter, Depends, HTTPException
from sqlalchemy.orm import Session
from app.config.database import get_db
from app.models.books import Books
from app.models.static_content import StaticContent
from app.services.gemini_ai import generate_summary, generate_qa_pairs, generate_podcast_script
from app.services.audio_generation import generate_podcast_audio
import redis
import hashlib
import json
import logging

logging.basicConfig(level=logging.INFO)

router = APIRouter(prefix="/student/generate", tags=["student-generation"])
redis_client= redis.Redis(host='localhost', port=6379, db=0)

def make_cache_keys_summary(book_id: int):
    raw_key = f"student_book_{book_id}"
    return hashlib.sha3_256(raw_key.encode()).hexdigest()

def make_cache_keys_qa(book_id: int):
    raw_key = f"student_book_{book_id}"
    return hashlib.sha3_256(raw_key.encode()).hexdigest()

def make_cache_keys_podcast(book_id: int):
    raw_key = f"student_book_{book_id}"
    return hashlib.sha3_256(raw_key.encode()).hexdigest()

@router.post("/books/{book_id}/summary")
def generate_summary_student(book_id: int, db: Session = Depends(get_db)):
    """
    Student-triggered on-demand summary generation.
    Only works for PUBLIC books. First student to request generates for all.
    """
    import time
    
    # Phase 1: Cache check
    cache_start = time.time()
    cache_key = make_cache_keys_summary(book_id)
    cached_summary = redis_client.get(cache_key)
    cache_time = time.time() - cache_start
    
    if cached_summary:
        logging.info(f"Summary for book {book_id} - cache_hit={cache_time:.4f}s")
        return {"message": "Summary fetched from cache", "summary": json.loads(cached_summary), "generated_now": False}
    
    # Phase 2: Database verification
    db_start = time.time()
    book = db.query(Books).filter(Books.book_id == book_id).first()
    db_time = time.time() - db_start
    
    if not book:
        logging.warning(f"Summary generation failed for book {book_id} - cache={cache_time:.4f}s db={db_time:.4f}s error=book_not_found")
        raise HTTPException(status_code=404, detail="Book not found")
    
    if book.is_public == 0:
        logging.warning(f"Summary generation failed for book {book_id} - cache={cache_time:.4f}s db={db_time:.4f}s error=book_not_public")
        raise HTTPException(status_code=403, detail="This book is confidential. AI content generation is not allowed for students.")
    
    # Phase 3: Check existing content
    content_check_start = time.time()
    content = db.query(StaticContent).filter(StaticContent.book_id == book_id).first()
    content_check_time = time.time() - content_check_start
    
    if content and content.summary_text:
        logging.info(f"Summary for book {book_id} already exists - cache={cache_time:.4f}s db={db_time:.4f}s content_check={content_check_time:.4f}s")
        return {"message": "Summary already exists", "summary": content.summary_text, "generated_now": False}
    
    # Phase 4: AI generation
    ai_start = time.time()
    try:
        print(f"Student generating summary for book {book_id}...")
        summary = generate_summary(book.pdf_url)
        ai_time = time.time() - ai_start
    except Exception as e:
        ai_time = time.time() - ai_start
        db.rollback()
        error_msg = str(e)
        logging.error(f"Summary generation failed for book {book_id} - cache={cache_time:.4f}s db={db_time:.4f}s content_check={content_check_time:.4f}s ai={ai_time:.4f}s error={error_msg}")
        if "429" in error_msg or "RESOURCE_EXHAUSTED" in error_msg:
            raise HTTPException(status_code=429, detail="API quota exhausted. Please try again later (wait 24 hours or contact admin for more keys).")
        raise HTTPException(status_code=500, detail=f"Generation failed: {error_msg}")
    
    # Phase 5: Database save
    save_start = time.time()
    if content:
        content.summary_text = summary
    else:
        content = StaticContent(book_id=book_id, summary_text=summary)
        db.add(content)
    
    db.commit()
    save_time = time.time() - save_start
    
    # Phase 6: Cache invalidation
    invalidate_start = time.time()
    admin_cache_key = f"summary_{book_id}"
    redis_client.delete(admin_cache_key)
    invalidate_time = time.time() - invalidate_start
    
    total_time = cache_time + db_time + content_check_time + ai_time + save_time + invalidate_time
    logging.info(f"Summary generation completed for book {book_id} - cache={cache_time:.4f}s db={db_time:.4f}s content_check={content_check_time:.4f}s ai={ai_time:.4f}s save={save_time:.4f}s invalidate={invalidate_time:.4f}s total={total_time:.4f}s")
    
    print(f"✓ Summary generated by student")
    return {"message": "Summary generated successfully!", "summary": summary, "generated_now": True}


@router.post("/books/{book_id}/qa")
def generate_qa_student(book_id: int, db: Session = Depends(get_db)):
    """
    Student-triggered on-demand Q&A generation.
    Only works for PUBLIC books. First student to request generates for all.
    """
    import time
    
    # Phase 1: Cache check
    cache_start = time.time()
    cache_key = make_cache_keys_qa(book_id)
    cached_qa = redis_client.get(cache_key)
    cache_time = time.time() - cache_start
    
    if cached_qa:
        logging.info(f"Q&A for book {book_id} - cache_hit={cache_time:.4f}s")
        return {"message": "Q&A fetched from cache", "qa": json.loads(cached_qa), "generated_now": False}
    
    # Phase 2: Database verification
    db_start = time.time()
    book = db.query(Books).filter(Books.book_id == book_id).first()
    db_time = time.time() - db_start
    
    if not book:
        logging.warning(f"Q&A generation failed for book {book_id} - cache={cache_time:.4f}s db={db_time:.4f}s error=book_not_found")
        raise HTTPException(status_code=404, detail="Book not found")
    
    if book.is_public == 0:
        logging.warning(f"Q&A generation failed for book {book_id} - cache={cache_time:.4f}s db={db_time:.4f}s error=book_not_public")
        raise HTTPException(status_code=403, detail="This book is confidential. AI content generation is not allowed for students.")
    
    # Phase 3: Check existing content
    content_check_start = time.time()
    content = db.query(StaticContent).filter(StaticContent.book_id == book_id).first()
    content_check_time = time.time() - content_check_start
    
    if content and content.qa_json:
        logging.info(f"Q&A for book {book_id} already exists - cache={cache_time:.4f}s db={db_time:.4f}s content_check={content_check_time:.4f}s")
        return {"message": "Q&A already exists", "qa": content.qa_json, "generated_now": False}
    
    # Phase 4: AI generation
    ai_start = time.time()
    try:
        print(f"Student generating Q&A for book {book_id}...")
        qa_json = generate_qa_pairs(book.pdf_url, 10)
        ai_time = time.time() - ai_start
    except Exception as e:
        ai_time = time.time() - ai_start
        db.rollback()
        error_msg = str(e)
        logging.error(f"Q&A generation failed for book {book_id} - cache={cache_time:.4f}s db={db_time:.4f}s content_check={content_check_time:.4f}s ai={ai_time:.4f}s error={error_msg}")
        if "429" in error_msg or "RESOURCE_EXHAUSTED" in error_msg:
            raise HTTPException(status_code=429, detail="API quota exhausted. Please try again later (wait 24 hours or contact admin for more keys).")
        raise HTTPException(status_code=500, detail=f"Generation failed: {error_msg}")
    
    # Phase 5: Database save
    save_start = time.time()
    if content:
        content.qa_json = qa_json
    else:
        content = StaticContent(book_id=book_id, qa_json=qa_json)
        db.add(content)
    
    db.commit()
    save_time = time.time() - save_start
    
    # Phase 6: Cache invalidation
    invalidate_start = time.time()
    admin_cache_key = f"qa_{book_id}"
    redis_client.delete(admin_cache_key)
    invalidate_time = time.time() - invalidate_start
    
    total_time = cache_time + db_time + content_check_time + ai_time + save_time + invalidate_time
    logging.info(f"Q&A generation completed for book {book_id} - cache={cache_time:.4f}s db={db_time:.4f}s content_check={content_check_time:.4f}s ai={ai_time:.4f}s save={save_time:.4f}s invalidate={invalidate_time:.4f}s total={total_time:.4f}s")
    
    print(f"✓ Q&A generated by student")
    return {"message": "Q&A generated successfully!", "qa": qa_json, "generated_now": True}


@router.post("/books/{book_id}/podcast")
def generate_podcast_student(book_id: int, db: Session = Depends(get_db)):
    """
    Student-triggered on-demand podcast generation.
    Only works for PUBLIC books. First student to request generates for all.
    """
    import time
    
    # Phase 1: Database verification
    db_start = time.time()
    book = db.query(Books).filter(Books.book_id == book_id).first()
    db_time = time.time() - db_start
    
    if not book:
        logging.warning(f"Podcast generation failed for book {book_id} - db={db_time:.4f}s error=book_not_found")
        raise HTTPException(status_code=404, detail="Book not found")
    
    if book.is_public == 0:
        logging.warning(f"Podcast generation failed for book {book_id} - db={db_time:.4f}s error=book_not_public")
        raise HTTPException(status_code=403, detail="This book is confidential. AI content generation is not allowed for students.")
    
    # Phase 2: Check existing content
    content_check_start = time.time()
    content = db.query(StaticContent).filter(StaticContent.book_id == book_id).first()
    content_check_time = time.time() - content_check_start
    
    if content and content.podcast_script and content.audio_url:
        logging.info(f"Podcast for book {book_id} already exists - db={db_time:.4f}s content_check={content_check_time:.4f}s")
        return {"message": "Podcast already exists", "script": content.podcast_script, "audio_url": content.audio_url, "generated_now": False}
    
    # Phase 3: AI script generation
    script_start = time.time()
    try:
        print(f"Student generating podcast for book {book_id}...")
        podcast_script = generate_podcast_script(book.pdf_url)
        script_time = time.time() - script_start
    except Exception as e:
        script_time = time.time() - script_start
        db.rollback()
        error_msg = str(e)
        logging.error(f"Podcast script generation failed for book {book_id} - db={db_time:.4f}s content_check={content_check_time:.4f}s script={script_time:.4f}s error={error_msg}")
        if "429" in error_msg or "RESOURCE_EXHAUSTED" in error_msg:
            raise HTTPException(status_code=429, detail="API quota exhausted. Please try again later (wait 24 hours or contact admin for more keys).")
        raise HTTPException(status_code=500, detail=f"Generation failed: {error_msg}")
    
    # Phase 4: Audio generation
    audio_start = time.time()
    try:
        audio_url = generate_podcast_audio(podcast_script, book_id)
        audio_time = time.time() - audio_start
    except Exception as e:
        audio_time = time.time() - audio_start
        db.rollback()
        error_msg = str(e)
        logging.error(f"Podcast audio generation failed for book {book_id} - db={db_time:.4f}s content_check={content_check_time:.4f}s script={script_time:.4f}s audio={audio_time:.4f}s error={error_msg}")
        if "429" in error_msg or "RESOURCE_EXHAUSTED" in error_msg:
            raise HTTPException(status_code=429, detail="API quota exhausted. Please try again later (wait 24 hours or contact admin for more keys).")
        raise HTTPException(status_code=500, detail=f"Generation failed: {error_msg}")
    
    # Phase 5: Database save
    save_start = time.time()
    if content:
        content.podcast_script = podcast_script
        content.audio_url = audio_url
    else:
        content = StaticContent(book_id=book_id, podcast_script=podcast_script, audio_url=audio_url)
        db.add(content)
    
    db.commit()
    save_time = time.time() - save_start
    
    # Phase 6: Cache invalidation
    invalidate_start = time.time()
    podcast_cache_key = f"podcast_{book_id}"
    audio_cache_key = f"audio_url_{book_id}"
    redis_client.delete(podcast_cache_key)
    redis_client.delete(audio_cache_key)
    invalidate_time = time.time() - invalidate_start
    
    total_time = db_time + content_check_time + script_time + audio_time + save_time + invalidate_time
    logging.info(f"Podcast generation completed for book {book_id} - db={db_time:.4f}s content_check={content_check_time:.4f}s script={script_time:.4f}s audio={audio_time:.4f}s save={save_time:.4f}s invalidate={invalidate_time:.4f}s total={total_time:.4f}s")
    
    print(f"✓ Podcast generated by student")
    return {"message": "Podcast generated successfully!", "script": podcast_script, "audio_url": audio_url, "generated_now": True}
